============================================================
MODEL EVALUATION REPORT
Timestamp: 2025-12-02T22:05:12.777680
============================================================

CATEGORY PERFORMANCE SUMMARY:
------------------------------

BASE MODELS WITH RAG:
  Average Similarity: 0.532
  Average Response Time: 7021.4 ms
  Models evaluated: 5

FINETUNED MODELS (NO RAG):
  Average Similarity: 0.396
  Average Response Time: 33877.8 ms
  Models evaluated: 4

FINETUNED MODELS WITH RAG:
  Average Similarity: 0.465
  Average Response Time: 13444.2 ms
  Models evaluated: 4

============================================================
TOP PERFORMING MODELS (by similarity):
------------------------------
1. Claude 3.5 Haiku
   Category: base_rag
   Similarity: 0.556
   Response Time: 9312.6 ms

2. Llama 3 8B
   Category: base_rag
   Similarity: 0.541
   Response Time: 4646.1 ms

3. Llama 3 Finetuned
   Category: finetuned
   Similarity: 0.538
   Response Time: 38943.8 ms

4. GPT-4o-mini
   Category: finetuned_rag
   Similarity: 0.537
   Response Time: 3232.4 ms

5. GPT-4o-mini
   Category: base_rag
   Similarity: 0.530
   Response Time: 5120.0 ms

============================================================