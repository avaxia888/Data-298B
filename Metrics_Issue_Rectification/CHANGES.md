# Casual Conversation Scoring Fix

## Problem Fixed

The Neil deGrasse Tyson AI chatbot was incorrectly giving non-zero retrieval scores for **casual conversations** (like "hi", "how are you") when it should return 0.

## Solution Implemented

Added intelligent query classification using **all-MiniLM-L6-v2** to distinguish between casual and informational queries and return appropriate scores.

## Changes Made

### New Functions in `utils.py`

#### 1. `get_classifier_model()`
- Lazy loading of all-MiniLM-L6-v2 model for classification
- Prevents repeated model loading

#### 2. `is_casual_conversation(query: str) -> bool`
- Detects casual conversations using semantic similarity
- Compares against predefined casual examples
- Returns `True` for greetings, pleasantries, thanks, goodbyes

#### 3. Enhanced `evaluate_retrieval()`
- Returns `0.0` scores for casual conversations
- Computes actual similarity for informational queries
- Adds classification metadata

#### 4. Optimized `rag_pipeline()`
- **Casual queries**: Skips retrieval, generates friendly response
- **Informational queries**: Full RAG pipeline with retrieval

## Results

### Before Fix
```python
# Casual conversation
evaluate_retrieval("hi", docs) 
# ‚Üí {"avg": 0.23, "top": 0.45}  ‚ùå Wrong!
```

### After Fix
```python
# Casual conversation
evaluate_retrieval("hi", docs)
# ‚Üí {"avg": 0.0, "top": 0.0, "classification": "casual"}  ‚úÖ Correct!

# Science question
evaluate_retrieval("what is a black hole", docs)
# ‚Üí {"avg": 0.85, "top": 0.92, "classification": "informational"}  ‚úÖ Correct!
```

## Performance Benefits

- ‚ö° **Faster responses** for casual queries (no retrieval)
- üìä **Accurate metrics** with proper 0 scores for casual conversations
- üîß **Resource efficient** - only retrieves for science questions

## Dependencies Used

- `sentence-transformers==4.1.0` (existing)
- `scikit-learn==1.7.2` (existing) 
- `numpy==2.3.3` (existing)

No new dependencies required - uses existing packages.

## Summary

The fix successfully resolves the issue where casual conversations like "hi" and "how are you" were getting non-zero retrieval scores. Now these queries correctly return 0.0 scores while maintaining proper similarity metrics for legitimate science questions.